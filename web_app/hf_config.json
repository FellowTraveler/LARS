{
    "access_gated": true,
    "access_token": "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",
    "model_id": "microsoft/Phi-3.5-mini-instruct",
    "gguf": false,
    "awq": false,
    "gguf_model_id": null,
    "gguf_filename": null,
    "quantize": "quanto",
    "quant_level": "int8",
    "hqq_group_size": 64,
    "push_to_hub": false,
    "torch_device_map": "cuda",
    "torch_dtype": "auto",
    "trust_remote_code": true,
    "use_flash_attention_2": false,
    "pipeline_task": "text-generation",
    "max_new_tokens": 500,
    "return_full_text": false,
    "temperature": 0.3,
    "do_sample": true,
    "top_k": 40,
    "top_p": 0.95,
    "min_p": 0.05,
    "n_keep": 0,
    "port": 9069,
    "model_list": [
        "mistralai/Mistral-Nemo-Instruct-2407",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-FP8",
        "hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4",
        "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
        "microsoft/Phi-3.5-mini-instruct",
        "microsoft/Phi-3.5-MoE-instruct",
        "microsoft/Phi-3-mini-4k-instruct",
        "microsoft/Phi-3-mini-128k-instruct",
        "microsoft/Phi-3-small-8k-instruct",
        "microsoft/Phi-3-small-128k-instruct",
        "microsoft/Phi-3-medium-4k-instruct",
        "microsoft/Phi-3-medium-128k-instruct",
        "CohereForAI/c4ai-command-r-plus",
        "CohereForAI/c4ai-command-r-v01",
        "google/gemma-2-2b-it",
        "google/gemma-2-9b-it",
        "google/gemma-2-27b-it",
        "Qwen/Qwen2-7B-Instruct",
        "Qwen/Qwen2-72B-Instruct",
        "alpindale/goliath-120b",
        "TheBloke/goliath-120b-AWQ"
    ]
}